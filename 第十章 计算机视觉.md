# 第十章 计算机视觉
## 计算机视觉概述
计算机视觉是一门研究如何对数字图像或视频进行高层理解的_交叉学科_，它与很多学科都有密切关系，如数字图像处理、模式识别、机器学习、计算机图形学等。
其中，数字图像处理可以看作偏低级的计算机视觉，多数情况下其_输入和输出都是图像_，而计算机系统的输出一般是模型、结构或符号信息。机器学习则为计算机视觉提供了_分析、识别和理解_的方法和工具，特别是近年来统计机器学习和深度学习都成了计算机视觉领域占主导地位的研究方法。计算机图形学与计算机视觉的关系_最为特殊_，计算及图形学研究的是如何_从模型生成图像或视频_的“正”问题，而计算机视觉研究的是如何_从输入图像中解析出模型_的“反”问题。近年来，计算机摄影学也逐渐得到重视，其关注的焦点是_采用数字信号处理_而非光学过程_实现新的成像可能_，典型的如光场相机、高动态成像、全景成像等经常用到计算机视觉算法。
与计算机视觉关系密切的另外一类学科来自_脑科学领域_，如认知科学、神经科学、心理学等。这些学科一方面_极大受益于_数字图像处理、计算摄影学、九三级视觉等学科带来的_图像处理和分析工具_，另一方面，它们所揭示的_视觉认知规律、视皮层神经机制_等对于计算机视觉领域的发展也起到了_积极的推动作用_。与脑科学进行交叉学科研究是非常有前途的研究方向。
> 例如，多层神经网络即深度学习就是受到认知神经科学的启发而发展起来的

## 数字图像的类型及机内表示
数字图像由一个个点组成，这些点称为像素（pixel），每个像素的亮度、颜色、距离等属性在计算机内表示为一个或多个数字。
如果是黑色图像（又称灰度图像），每个像素由一个亮度值表示，通常用一个字节表示，最小值为0（最低亮度，黑色），最大值为255（最高亮度，白色）。
如果是彩色图像，每个像素的颜色通常用分别代表红绿蓝的三个字节表示，如果蓝色分量是0，则表示该像素点吸收了全部的蓝色光，如果是255则代表该像素点反射了全部亮蓝色光。
除了黑色或彩色图像，还有一类相机可以采集深度信息，即RGBD图像。RGBD图像对每个像素，除了赋予红绿蓝彩色信息，还会有一个值表达深度，即该像素距离摄像机的距离（depth)，其单位取决于相机的测量精度，一般为毫米，至少用两个字节表示。深度信息本质上反映了物体的3D形状信息，这类相机在体感游戏、自动驾驶、机器人导航等领域有潜在的广泛应用价值。
此外，计算机视觉处理的图像或视频还可能来自超越人眼的成像设备，它们所采集的电磁波段信号超出了人眼所能感知的可见光电磁波段范围，如红外、紫外、X光成像等。这些成像设备及后续的视觉处理算法在医疗、军事、工业等领域有非常广泛的应用。
## 常用计算机视觉模型和关键技术
除了“几何”这一传统计算视觉领域，自2000年来，“机器学习”分支开始异军突起，这一分支的核心思路是采用**模式识别和机器学习方法**，解决计算机视觉中的物体检测、跟踪、识别、分类、分割、预测甚至3D重建等任务。
其核心技术路线是将这些问题定义为从输入图像/视频_直接求解标签的函数拟合问题_，采用**数据驱动**的机器学习方法来求解待拟合的函数（大多数时候是求解函数的参数）。
下面重点介绍“机器学习”分支的基本情况，尽管计算机视觉任务繁多，但大多数任务本质上可以建模为广义的函数拟合问题，![](https://tva1.sinaimg.cn/large/008i3skNgy1gz9g65trr4j30u0140dli.jpg)，即对于任意输入图像x，需要学习一个以θ为参数的函数F，使得![](https://tva1.sinaimg.cn/large/008i3skNgy1gz9g69qfcfj307c034dfq.jpg)，其中y可能有两大类：
1. y为类别标签，对应模式识别或机器学习中的分类问题，这类任务的特点是_输出y为有限种类的离散变量_。
2. y为连续变量或向量或矩阵，对应模式识别或机器学习中的回归问题，如距离估计、目标预测、语义分割等视觉任务。在这些任务中，y或者连续的变量，或者是一个向量，或者是每个像素有一个所属物体类别的编号。
实现上述函数的具体方法很多，多数视觉模型和算法可以被分成两大类：一类是2021年以来应用最广泛的深度模型和学习方法，另一类是浅层模型和学习方法。
### 基于浅层模型的方法
实现上述视觉任务的函数Fθ通常都是非常复杂的，为此，一种可能的解法是遵循分而治之的思想，对其进行分步、分阶段求解，一个典型的视觉任务实现流程包括以下四个步骤：图像预处理、特征设计与提取、特征汇聚或变换、分类器/回归器
1. 图像预处理过程p
用于实现目标对齐、几何归一化、亮度或颜色矫正等处理，从而_提高数据的一致性_，该过程一般人为设定。
2. 特征设计与提取过程q
其功能是从预处理后的图像中提取描述图像内容的特征，这些特征可能反映图像的低层（如边缘）、中层（如部件）或高层（如场景）特性，一般由专家知识进行人工设计。
3. 特征汇聚或特征变换h
其功能是对前步提取的局部特征（一般是向量）进行统计汇聚或降维处理，从而得到维度更低、更利于后续分类或回归过程的特征。该过程一般通过专家设计的统计建模方法实现。
4. 分类器或回归器函数的设计与训练
其功能是采用机器学习或模式识别的方法，基于一个有导师的训练集（x是训练图像，y是其类别标签）学习得到，通过有监督的机器学习实现

不难发现，上述流程带有强烈的“人工设计”色彩，不仅以来专家知识进行划分，更依赖专家知识选择和设计各步骤的函数，这与后来出现的深度学习方法依赖大量数据进行端到端的自动学习形成了鲜明对比。

### 基于深度模型的视觉方法
事实上，深度卷积神经网络（DCNN）也是通过滤波器提取局部特征，然后通过逐层卷积和汇聚（池化），将“小局部”特征逐级合并为“越来越大的局部”特征，甚至最终通过**全连接**形成全局特征，_实现从底层特征（如边缘）到中层特征（如部件或属性）再到高层特征（如类别标签）的逐级抽象_。
但与浅层模型相比，深度模型的滤波器参数（权重）不是认为设定的，而是通过神经网络的BP算法等训练学习而来，而且DCNN模型以统一的卷积作为手段，实现了从小局部到大局部（即所谓层级感受野）特征的提取。
1. 基于深度卷积神经网络的图像分类与识别
与传统的图像分类或识别方法相比，基于深度学习的方法不再需要经过人工设计的方法来提取特征，而是直接将图像输入一个CNN，该网络的输出即作为输入图像的特征。这里的CNN不是任意的，需要经过两个步骤来获得：第一步要设计或选择好CNN网络结构，或者其他根据计算量等需求自行设计的网络；第二步则需要利用一个训练集对网络中的大量参数（主要是各神经节点的权重）进行优化，使之能够准确分类训练集中的不同类别的图像。
2. 基于深度模型的目标检测技术
目标检测是计算机视觉中的一个基础问题，其定义某些感兴趣的特定类别组成前景，其他类别为背景。我们需要设计一个目标检测器用来在输入图像中找到所有前景物体中的位置以及它们所属的具体类别，物体的位置用长方形物体边框描述。
实际上，目标检测问题可以简化为图像区域的分类问题，如果在一张图像中提取足够多可能的**物体候选位置**，那么只需要将所有候选位置进行分类，即可找到含有物体的位置。在实际操作中，常常再引入一个边框回归器用来修正候选框的位置，并在检测器后接入一个后处理操作去除属于同一物体的重复检测框。
R-CNN最早将深度学习应用在目标检测中，R-CNN目标检测一般包括一下步骤：①输入一张图像，使用无监督算法提取约2000个物体的可能位置 ②将所有候选区域取出并缩放为相同的大小，输入卷积神经网络中提取特征 ③使用SVM对每个区域的特征进行分类
R-CNN的最大缺点是尽管所有候选区域中存在大量的重叠和冗余，它们都还是分别经过卷积神经网络进行计算，使得计算代价非常大。为了提高计算效率，Fast R-CNN对同一张图像_只提取一次卷积特征_，此后接入ROI Pooling层，将特征图上不同尺寸的_感兴趣区域_取出并池化为固定尺寸的特征，再将这些特征用Softmax进行分类。
3. 基于全卷积核网络的图像分割
对于像素级的分类和回归任务（如图像分割和边缘检测），代表性的深度网络模型是**全卷积核网络(fully convolutional network, FCN)**。经典的DCNN在卷积层之后使用了全连接层，而全连接层中_单个个神经元的感受野是整张图像_，破坏了神经元之间的空间关系，因此不适用于像素级视觉处理任务。
为此，FCN_去掉了全连接层_，_代之以1×1的卷积核和反卷积层_，从而能够在保持神经元空间关系的前提下，通过反卷积操作获得与输入图像大小相同的输出。进一步，FCN通过不同层、多尺度卷积特征图的融合为像素级的分类器和回归任务提供了一个高效的框架。
4. 融合图像和语言模型的自动图题生成
图像自动标题的目标是_生成输入图像的文字描述_，即看图说话。深度学习方法应用于该问题的代表性思路是使用CNN学习图像表示，然后采用循环神经网络或长短期记忆模型LSTM学习语言模型，并以CNN特征输入初始化RNN/LSTM的隐层节点，_组成混合网络进行端到端的训练_。