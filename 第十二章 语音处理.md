# 第十二章 语音处理
语音处理涉及许多学科，它以心理、语言、声学等为基础，以信息论、控制论、系统论等理论作为指导，通过应用信号处理、统计分析和模式识别等现代技术手段，发展成为新的学科。
## 语音的基本概念
语音是指人类通过发音器官发出来的、具有一定意义的、目的是用来进行_社会交际_的声音。
语音的物理基础主要有音高、音强、音长、音色。音高指声波频率，即每秒振动多少次；音强指声波振幅的大小；音长指声波振动持续时间的长短；音色指声音的特色和本质。
语音经过采样以后，在计算机中以**波形文件**的方式进行存储，这种波形文件反映了语音在_时域上的变化_。
人们可以从语音的波形中判断语音音强、音长等参数的变化，但却很难从波形中分辨出不同的_语音内容或不同的说话人_。为了更好地反映不同语音的内容或音色差别，需要对语音记性频域上的转换，即提取语音**频域的参数**。
通过对语音进行离散傅里叶变换可以得到傅里叶谱，在此基础上根据人耳的听感特性，将语音信号在频域上划分成不同子带，进而可以得到梅尔频率倒谱系数。（梅尔倒谱系数是一种能够近似反映人耳听觉特点的频域参数）
## 语音识别
语音识别是将语音自动转换为文字的过程。
语音识别系统主要包括四个部分：特征提取、声学模型、语言模型、解码搜索。
### 语音识别的特征提取
语音识别的难点之一在于语音信号的复杂性和多变性。在一段语音信号中，仅少量的信息与语音识别有关，这些信息被淹没在大量信息中，因此充满了变化性。
语音特征提取即是在原始语音信号中提取出_与语音识别最相关的信息_，滤除其他无关信息。比较常用的声学特征有三种，即_梅尔频率倒谱系数、梅尔标度滤波器组特征、感知线性预测倒谱系数_。

### 语音识别的声学模型
声学模型承载着声学特征与建模单元之间的映射关系。
在训练声学模型之前需要选取建模单元，建模单元可以是音素、音节、词语等，其单元粒度依次增加。由于词语的粒度较大，很难充分训练模型，因此通常采用粒度较小的音素作为建模单元。
语音中存在协同发音的现象，即音素是上下文相关的，故一般采用三音素进行声学建模。
比较经典的声学模型是混合声学模型，大致可以概括为两种：基于高斯混合模型-隐马尔可夫模型的模型和基于深度神经网络-隐马尔可夫模型的模型。
1. 基于高斯混合模型-隐马尔可夫模型的模型
隐马尔可夫模型的参数主要包括状态间的转移概率以及每个状态的概率密度函数（也称出现概率），一般用高斯混合模型表示。
对于小词汇量的自动语音识别任务，通常使用上下文无关的音素状态进行建模。对于中等和大词汇量的自动语音识别任务，则使用上下文相关的音素记性建模。
高斯混合模型用来估计观察特征（语音特征）的观测概率，而隐马尔可夫模型则被用于描述语音信号的动态变化（即状态间的转移概率）。
2. 基于深度神经网络-隐马尔可夫模型的模型
基于深度神经网络-隐马尔可夫模型的声学模型是指_用深度神经网络模型替换上述模型的高斯混合模型_，深度神经网络模型可以是深度循环神经网络和深度卷及网络等。
该模型的建模单元为聚类后的三音素状态，神经网络用来估计观察特征（语音特征）的观测概率，而隐马尔可夫模型则被用于描述语音信号的动态变化（即状态间的转移概率）。
与基于高斯混合模型的声学模型相比，这种基于深度神经网络的声学模型具有两方面优势：一是深度神经网络可以利用语音特征的**上下文信息**；二是深度神经网络能学习**非线性的更高层次特征表达**。因此，基于深度神经网络-隐马尔科夫模型的声学模型的性能显著超越基于高斯混合模型-隐马尔可夫模型的声学模型，已成为目前主流的声学建模技术。
### 语音识别的语言模型
语言模型是_根据语言客观事实_而进行的_语言抽象数学建模_。语言模型亦是一个概率分布模型，用于计算任何句子发生的概率。
在语音识别系统中，语言模型的作用是在解码过程中从语言层面上_限制搜索路径_。
语言模型的评价指标是语言模型在测试集上的困惑度，该值反映句子不确定性的程度，因此构建语言模型时，目标就是寻找困惑度较小的模型，使其尽量逼近真实语言的分布。
常用的语言模型有N元文法语言模型和循环神经网络语言模型。尽管RNN的性能由于N元文法语言模型，但其训练比较耗时且解码时识别速度较慢，因此工业界仍采用N元文法语言模型。

### 语音识别的解码搜索
解码搜索的主要任务是在由声学模型、发音词典、语言模型构成的搜索空间中寻找最佳路径。
解码时需要用到声学得分和语言得分，分别由声学模型和语言模型计算得到。其中，每处理一帧特征就会用到声学得分，而语言得分只有在解码到**词级别**才会涉及，一个词覆盖多帧语音特征。故此解码时声学得分和语言得分存在较大的数值差异，为了避免这种差异，解码时会引入一个参数对语言得分进行平滑，从而使两种得分具有相同的尺度。
构建解码空间的方法可以概括为两类——静态的解码和动态的解码，静态的解码预先将整个静态网络加载到内存中，而动态的解码动态地构造和销毁解码网络。
解码所使用的搜索算法大概可以分成两类，一类是采用时间同步的方法（如维特比算法），另一类是时间异步的方法（如A星算法）。

### 基于端到端的语音识别方法
上述混合声学模型存在两点不足：一是神经网络模型的性能受限于高斯混合模型-隐马尔可夫模型的精度；二是训练过程过于繁复。为了解决这些不足，研究人员提出了端到端的语音识别方法，一类是基于联结时序分类的端到端声学建模方法；另一类是基于序列模型的端到端语音识别方法。前者只是实现了声学建模的端到端，而后者实现了真正意义上的端到端语音识别。

基于联结时序分类的端到端声学模型的核心思想是引入了一种新的训练准则联结时序分类，这种损失函数的优化目标是输入和输出在句子级别对齐，而不是帧级别对齐，因此不需要向混合声学模型那样生成强制对齐信息，而是_直接对输入特征序列到输出单元序列的映射关系建模_，极大地简化了声学模型训练的过程，_但是语言模型还需要单独训练以构建解码的搜索空间_。
基于联结时序分类的端到端模型的建模单元是音素甚至可以是字，这种单元粒度的变化带来的优点包括两方面：一是增加语音数据的冗余度，提高音素的区分度；二是在不影响准确率的情况下加快解码速度。

基于序列模型的端到端语音识别方法将声学模型、发音词典、语言模型联合为一个模型进行训练。目前基于序列模型的端到端语音识别系统主要包括两种，一种是基于注意力机制的端到端模型，另一种是基于循环神经网络转换器的端到端模型。

基于注意力机制的端到端模型是基于循环神经网路的编码-解码结构的，编码器用于将_不定长的输入序列_映射成_定长的特征序列_，注意力机制用于提取编码器的_编码特征序列中的有用信息_，而解码器则_将该定长序列拓展成输出单元序列。_
尽管这种模型取得了不错的性能，但其性能远不如混合声学模型。
> 近期谷歌提出了一种新的多头注意力机制的端到端模型，当训练数据达到数十万小时时，其性能可以接近混合声学模型

基于循环神经网络转换器的端到端模型是_在CTC模型的基础上_，由Alex Graves引入一个**联结器**，将语言模型和声学模型组合到一起，生成一个联合的解码网络，同时能够进行端到端的联合优化。
模型包括转换网络（编码器）、预测网络、联结网络。转换网络类似于前面的解码器，负责_将声学特征序列转换为声学编码状态_。预测器本质上是一个语言模型部件，负责根据输入的_上一时刻_预测的非空语言标记和语言状态预测出语言状态。联结器负责根据声学状态和语言状态整合来预测一个新的输出标记。

## 语音合成
语音合成的主要功能是将任意的输入文本转换成自然流畅的语音输出。语音合成系统主要可以分为_文本分析模块、韵律处理模块、声学处理模块_，其中文本分析模块可以看作系统的前端，后两个模块为系统的后端。
文本分析模块的主要任务是对输入的任意文本进行分析，输出尽可能多的语言学信息，为后端的语音合成器提供必要信息。对于汉语语音合成系统，文本分析的处理流程通常包括文本预处理、文本规范化、自动分词、词性标注、多音字消节奏预测等。
韵律处理是文本分析模块的目的所在，节奏、时长的预测都基于文本分析的结果。作为语音合成系统中_承上启下_的模块，韵律模块实际上是语音合成系统的_核心部分_，极大地影响着最终合成语音的自然度。
声学处理模块根据前两个模块提供的信息生成**自然语音波形**。语音合成系统的合成阶段可以简单概括为两种方法，一种是**基于时域波形的拼接合成方法**，声学处理模块根据韵律处理模块提供的信息并在大规模语料库中挑选最合适的语音单元，然后通过拼接算法生成自然语音波形；另一种是**基于语音参数的合成方法**，声学处理模块的主要任务是根据韵律和文本信息的指导来得到语音参数，然后通过语音参数合成器来生成自然语音波形。

## 语音转换
语音转换是通过语音处理手段改变语音中的说话人个性信息，使改变后的语音听起来像是由另一个人发出的。
语音转换首先提取说话人身份相关的**声学特征参数**，然后用改变后的声学特征参数合成出接近目标说话人的语音。实现一个完整的语音转换系统一般包括离线训练和在线转换两个阶段，在训练阶段，首先提取源说话人和目标说话人的个性特征参数，其次根据某种匹配规则建立两者之间的匹配函数；在转换阶段，利用生成的匹配函数对源说话人的个性特征参数进行转换，最后利用转换后的特征参数合成出接近目标说话人的语音。
