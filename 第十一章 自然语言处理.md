# 第十一章 自然语言处理
## 自然语言处理概述
人工智能包括运算智能、感知智能、认知智能、创造智能。其中，运算智能是记忆和计算的能力，这一点计算机远超人类。感知智能是电脑感知环境的能力，包括听觉、视觉、触觉等。近年来随着深度学习的成功应用，语音识别和图像识别获得了很大的进步。
认知智能包括语言理解、知识和推理，其中，语言理解包括词汇、句法、语义层面的理解，也包括篇章级别和上下文的理解；知识是人们对客观事务认识的体现以及运用知识解决问题的能力；推理则是根据语言理解和知识，在已知的条件下根据一定的规则或者规律推演出某种可能的结果的思维过程。
创造智能体现了对魏建国、未发生的事物，运用经验，通过想象力设计、实验、验证并予以实现的智力过程。
随着感知智能的大幅进步，人们的焦点逐渐转向了认知智能，其中自然语言处理处在认知智能最核心的地位，它的进步会引导知识图谱和推理能力的进步，从而推动人工智能整体的进展。
自然语言处理通过对词、句子、篇章进行分析，对内容中的人物、时间、地点等进行理解，并在此基础上支持一系列技术，如翻译、问答、阅读理解、知识图谱等。
自然语言处理是人工智能的一个分支，用于分析、理解、生成自然语言。
自然语言处理框架图：
![](https://tva1.sinaimg.cn/large/008i3skNgy1gz9g6gpepsj30u0140dli.jpg)
自然语言处理中四个最基本的任务——分词、词性标注、依存句法分析、命名实体识别。
1. 分词模块负责将输入的汉字序列切分成单词序列，该模块是自然语言处理中最底层、最基础的任务，其输出直接影响后续的自然语言处理模块。
2. 词性标注模块负责为分词结果中的每个单词标注一个磁性。
3. 依存句法分析负责预测句子中单词与单词之间的依存关系，并用树状图结构来表示整句的句法结构。
4. 命名实体识别负责从文本中识别出具有特定意义的实体，如人名、地名、机构名、专有名词等。

计算机出现之后就有了人工智能的研究，而人工智能最早的研究就是机器翻译以及自然语言处理，基本上可以划分为三个阶段：
_第一阶段（20世纪60-80年代）：_**基于规则**来建立词汇、句法语义分析、问答、聊天和机器翻译系统。好处是规则可以利用人类的内省知识，不依赖数据，可以快速起步；缺点是覆盖面不足，规则管理和可拓展性一直没有解决。
_第二阶段（20世纪90年代开始）：_**基于统计的机器学习**开始流行，很多NLP开始用基于统计的方法来做。主要思路是利用_带标注_的数据，基于人工定义的特征建立机器学习系统，并利用数据经过学习确定机器学习系统的参数。运行时利用学习得到的参数对输入数据进行解码，得到输出。
_第三阶段（2008年之后）：_深度学习开始在语音和图像识别发挥威力，随之NLP研究者开始把目光转向深度学习。先是把深度学习用于特征计算或者建立一个新的特征，然后再原有的统计学习框架下体验效果。2014年以来，人们尝试直接通过深度学习建模，进行端到端的训练。

深度学习技术_根本地_改变了自然语言处理技术，使之进入崭新的发展阶段，总结一下，主要体现在以下几个方面：
1. 神经网络的端对端训练使自然语言处理技术不需要人工进行特征提取，只要准本号足够多的标注数据即可
2. 词嵌入的思想使得词汇、短语、句子甚至篇章的表达可以在大规模语料上进行训练，得到一个在多维语义空间上的表达，使得词汇之间、短语之间、句子之间、篇章之间的予以距离可以计算
3. 基于神经网络训练的语言模型可以更加精准地预测下一个词或者句子的出现概率
4. 循环神经网络可以对一个不定长的句子进行编码，描述句子的信息
5. 编码-解码（encoder-decoder)技术可以实现一个句子到另外一个句子的变换，这个技术是神经机器翻译、对话生成、问答、转述的核心技术
6. 强化学习使得自然语言系统可以通过用户或者环境的反馈调整神经网络各级的参数，从而改进系统性能

目前主流的自然语言处理范式是**预训练+微调**，其基本思想是将训练大而深的端对端的神经网络模型分为两步：首先在大规模文本数据上通过_无监督_学习预训练大部分的参数，然后在具体的自然语言处理任务上添加与任务相关的神经网络。通过预训练从大规模文本数据中学到的语言知识可_迁移到下游的自然语言处理_，预训练模型也从单语言预训练模型拓展到多语言预训练模型和多模态预训练模型。

下面分别介绍自然语言处理中最重要的三个技术——机器翻译、自然语言人机交互、智能问答。

## 机器翻译
机器翻译从被提出发展到现在，从方法上可以分为基于规则的机器翻译、基于实例的机器翻译、基于统计的机器翻译和神经机器翻译四个阶段。
随着计算能力的进一步提升，特别是基于GPU的并行化训练的快速发展，基于深度神经网络的方法在自然语言处理中逐渐受到关注，随着编码器和解码器框架以及注意力机制的提出，神经机器翻译全面超过了统计机器翻译，机器翻译进入了神经网络时代。
### 编码器解码器翻译模型
机器翻译建模可以看作是一个特殊的语言模型，机器翻译使用目标语言的语言模型来预测某个句子的生成概率，但是需要以源语言句子作为条件，为了解决数据稀疏问题，我们往往采用一种编码的方式来表示输入的句子。
循环神经网络便是常用的对句子进行编码的方式，循环神经网络包含三个部分，分别是输入层、隐含层、输出层。循环神经网络每个时刻根据_上一个时刻_的隐含层和_当前的输入_生成当前时刻的隐含状态，并基于当前的隐含状态预测当前时刻的输出。
每输入一个词都会同当前时刻的隐含状态进行融合生成一个_包含当前词信息和前面所有词信息_的新的隐含状态。当把整个句子所有的词输入进去之后，最后的隐含状态理论上包含了所有词的信息，便可以作为整个句子的语义向量表示，该语义向量称为源语言句子的上下文向量。
编码器将源语言句子编码为一个源语言句子的上下文向量，编码器的任务是根据编码器生成的上下文向量生成目标语言句子的符号化表示。给定源语言的上下文向量，解码器循环神经网络首先产生第一个隐含状态，并给予该隐含状态预测第一个目标词；然后第一个目标词会被作为下一个时刻的输入，联通第一个隐含状态以及上下文向量来产生第二个隐含状态，该隐含状态包含了目标语言句子第一个词的信息和源语言句子的信息，并并用来预测第二个词，如此循环下去，知道预测到一个句子的结束符\</S\>为止。
### 注意力机制的引入
基于编码器解码器框架的神经机器翻译模型在翻译表较短的句子时效果还可以，但是在翻译比较长的句子时，由于_最先输入的词的信息在经过多步的循环神经单元的运算后很难被保留下来_，从而导致翻译质量下降比较严重。
注意力机制的引入进一步提高了编码器解码器框架在长句子上的翻译质量，使得神经机器翻译模型的翻译质量全面超越了基于统计的翻译模型。
不同于传统的编码器解码器框架_只使用最后一个隐含状态作为解码器的输入_，注意力网络首先使用匹配函数计算任意一个编码器隐含状态和前一时刻解码器状态的匹配得分；然后使用Softmax函数将该得分_标准化_成一个编码器隐含状态序列上的概率，该概率作为权重被用来对编码器隐含状态序列的_所有隐含状态_进行_加权_，从而得到该时刻的上下文向量。基于该上下文向量，便可以使用标准化循环神经网络解码器生成当前时刻的隐含状态。
使用注意力机制的解码器在生成目标语言词时，对源语言句子里的词信息的考量有侧重，这种侧重的程度便是通过标准化后的概率来体现，而概率的计算则是通过比较、匹配编码器隐状态和解码器隐状态得到。
### 完全基于注意力网络的神经翻译模型
注意力网络通过将源语言句子的隐含状态和目标语言句子的隐含状态_直接链接_，从而缩短了源语言词的信息到生成生成对应目标语言词的**传递路径**，显著提高了翻译质量。
基于循环神经网络的编码器解码器，每个词的隐含状态都_依赖于前一个词的信息，所以编码的状态是顺序生成的_，但这种编码顺序生成的方式严重影响了模型的并行能力。此外，尽管基于词的循环神经单元可以解决梯度消失或爆炸的问题，然而相距太远的词的信息仍然不能被保证被考虑进来。
为了同时解决这些问题，可以将两个额外的注意力网络引入编码器和解码器的内部，分别用于解决源语言句子和目标语言句子_内部词语之间的依赖关系_。基于这样的考虑，Vaswani等人提出了完全基于注意力网络的神经翻译模型Transformer。
Transformer模型同原来的基于循环网络模型的最大不同在于，使用_自注意力网络取代循环神经网络来作为编码器和解码器的处理单元_。
以编码器为例，为了得到第n层t时刻的隐含状态，我们使用分组注意力网络，利用第n-1层_t时刻_的隐含状态去同第n-1层_所有时刻的隐含状态_计算注意力权重，并使用其将n-1层的隐含状态_加权_得到第n层t时刻的隐含状态。一方面，该方法的计算并不像循环神经网络一样从左到右来生成隐含状态，词与词之间直接_通过注意力机制联系_起来，解决了长距离的依赖问题；另一方面，分组注意力机制的引入提供了_从多个角度_去获取上下文信息的能力。解码器端使用类似的自注意力机制，不同之处在于需要使用**掩码**将句子后边的信息屏蔽掉。由于自注意力网络不能像循环神经网络那样天然地考虑句子里词的**顺序信息**，所以将**位置编码**引入进来。
